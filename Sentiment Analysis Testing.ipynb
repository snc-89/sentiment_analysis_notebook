{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested our sentiment analysis against already labeled data. This labeled data is from the VADER python module, which was delveloped by researchers at George Institute of Technology. Their paper can be found here, and the dataset can be found here also:\n",
    "http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf\n",
    "https://github.com/apanimesh061/VaderSentimentJava/blob/master/src/test/resources/tweets_GroundTruth_vader.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:   0.8035580055124029\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "\n",
    "with open('files/vader_texts_and_scores.json') as f:\n",
    "    vader_sentiments = json.load(f)\n",
    "f.close\n",
    "with open('files/our_texts_and_scores.json', 'r') as f:\n",
    "    our_sentiments = json.load(f)\n",
    "f.close\n",
    "\n",
    "#turn sentiment scores into negative (-1), neutral(0), positive(1) categories\n",
    "def categorise_scores(dictionary):\n",
    "    for i,text in enumerate(dictionary['vader']):\n",
    "        if text['sentiment'] > 0:\n",
    "            dictionary['vader'][i]['sentiment'] = 1\n",
    "            continue\n",
    "        if text['sentiment'] < 0:\n",
    "            dictionary['vader'][i]['sentiment'] = -1\n",
    "            continue\n",
    "        dictionary['vader'][i]['sentiment'] = 0\n",
    "\n",
    "categorise_scores(vader_sentiments)\n",
    "categorise_scores(our_sentiments)\n",
    "\n",
    "#extracting texts and scores from dictionaries as lists to turn into dataframe\n",
    "vader_texts, vader_scores, our_texts, our_scores, our_magnitude = ([] for i in range(5))\n",
    "for vader,ours in zip(vader_sentiments['vader'],our_sentiments['vader']):\n",
    "    vader_texts.append(vader['text'])\n",
    "    vader_scores.append(vader['sentiment'])\n",
    "    our_texts.append(vader['text'])\n",
    "    our_scores.append(ours['sentiment'])\n",
    "    our_magnitude.append(ours['magnitude'])\n",
    "\n",
    "#turn to dataframes and sort them by text alphabetically because they're not in the same order initially\n",
    "vaders = pd.DataFrame({'texts': vader_texts, 'y_true': vader_scores})\n",
    "ours = pd.DataFrame({'texts': our_texts,'pred': our_scores,'magnitude': our_magnitude})\n",
    "vaders.sort_values(by=['texts'])\n",
    "ours.sort_values(by=['texts'])\n",
    "\n",
    "#join the dataframes together and filter out 0 values\n",
    "df = pd.concat([ours,vaders], axis=1)\n",
    "sans_0 = df[(df.pred != 0) & (df.y_true != 0)]\n",
    "y_true = sans_0.y_true\n",
    "prediction = sans_0.pred\n",
    "print(\"accuracy score:  \",accuracy_score(y_true, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
